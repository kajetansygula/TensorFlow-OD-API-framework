{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d7fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c028edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset name\n",
    "training_dataset_name = 'training_demo'\n",
    "\n",
    "# Paths\n",
    "LABEL_MAP_PATH = os.path.join('Tensorflow', 'workspace', training_dataset_name, 'annotations', 'label_map.pbtxt')\n",
    "PREPROCESSING_SCRIPTS_PATH =  os.path.join('Tensorflow','scripts','preprocessing')\n",
    "ANNOTATIONS_PATH = os.path.join('Tensorflow', 'workspace', training_dataset_name, 'annotations')\n",
    "TRAIN_SET_PATH = os.path.join('Tensorflow', 'workspace', training_dataset_name, 'images', 'train')\n",
    "TEST_SET_PATH = os.path.join('Tensorflow', 'workspace', training_dataset_name, 'images', 'test')\n",
    "PRETRAINED_MODEL_PATH = os.path.join('Tensorflow', 'workspace',training_dataset_name, 'pre-trained-models')\n",
    "MODELS_PATH = os.path.join('Tensorflow', 'workspace',training_dataset_name, 'models')\n",
    "\n",
    "# Create new folders\n",
    "# !mkdir {PREPROCESSING_SCRIPTS_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f434f8d",
   "metadata": {},
   "source": [
    "#### Create a label map file (*.pbtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd28afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_name = 'training_demo'\n",
    "\n",
    "labels = [{'name':'godzilla', 'id':1}]\n",
    "\n",
    "with open(LABEL_MAP_PATH, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c1f95",
   "metadata": {},
   "source": [
    "#### Creating TensorFlow Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7d8716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [................................................................................] 6410 / 6410        1 file(s) moved.\n"
     ]
    }
   ],
   "source": [
    "# Set up file information\n",
    "tf_records_script_url = 'https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py'\n",
    "tf_records_script_name = 'generate_tfrecord.py'\n",
    "\n",
    "# Download and move file to specific directory\n",
    "wget.download(tf_records_script_url)\n",
    "!move {tf_records_script_name} {PREPROCESSING_SCRIPTS_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "089b559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow\\workspace\\training_demo\\annotations\\train.record\n",
      "Successfully created the TFRecord file: Tensorflow\\workspace\\training_demo\\annotations\\test.record\n"
     ]
    }
   ],
   "source": [
    "!python {os.path.join(PREPROCESSING_SCRIPTS_PATH, tf_records_script_name)} -x {TRAIN_SET_PATH} -l {LABEL_MAP_PATH} -o {os.path.join(ANNOTATIONS_PATH, 'train.record')} \n",
    "!python {os.path.join(PREPROCESSING_SCRIPTS_PATH, tf_records_script_name)} -x {TEST_SET_PATH} -l {LABEL_MAP_PATH} -o {os.path.join(ANNOTATIONS_PATH, 'test.record')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1e88f",
   "metadata": {},
   "source": [
    "#### Configuring a training job\n",
    "Choose model for transfer learning: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df97c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model (example: SSD ResNet50 V1 FPN 640x640)\n",
    "pre_trained_model_url = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "pre_trained_model_name = 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8'\n",
    "\n",
    "wget.download(pre_trained_model_url)\n",
    "!move {pre_trained_model_name +'.tar.gz'} {PRETRAINED_MODEL_PATH}\n",
    "!cd {PRETRAINED_MODEL_PATH} && tar -zxvf {pre_trained_model_name +'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45245002",
   "metadata": {},
   "source": [
    "#### Configure the training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8602c26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) copied.\n"
     ]
    }
   ],
   "source": [
    "# Create a directory of the new model\n",
    "new_model_name = 'my_ssd_resnet50_v1_fpn'\n",
    "!cd {MODELS_PATH} && mkdir {new_model_name}\n",
    "\n",
    "NEW_MODEL_PATH = os.path.join('Tensorflow', 'workspace',training_dataset_name, 'models', new_model_name)\n",
    "\n",
    "# Copy existing pipeline to the new directory \n",
    "!copy {os.path.join(PRETRAINED_MODEL_PATH, pre_trained_model_name, 'pipeline.config')} {NEW_MODEL_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2f0a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline path\n",
    "PIPELINE_CONFIG_PATH = os.path.join('Tensorflow', 'workspace', training_dataset_name, 'models', new_model_name, 'pipeline.config')\n",
    "\n",
    "# Read pipeline.config file\n",
    "config = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d37374af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editing pipeline \n",
    "# Credit: https://stackoverflow.com/questions/55323907/dynamically-editing-pipeline-config-for-tensorflow-object-detection\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(PIPELINE_CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60be2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(PRETRAINED_MODEL_PATH, pre_trained_model_name, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = LABEL_MAP_PATH\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(ANNOTATIONS_PATH, 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = LABEL_MAP_PATH\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(ANNOTATIONS_PATH, 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "373eee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite pipeline.config\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(PIPELINE_CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf9ba68",
   "metadata": {},
   "source": [
    "#### Create a command line to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e492c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up number of steps\n",
    "number_of_steps = 2000\n",
    "\n",
    "# Define necessary paths\n",
    "TRAINING_SCRIPT_PATH = os.path.join('Tensorflow', 'models-master', 'research', 'object_detection', 'model_main_tf2.py')\n",
    "\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps={}\".format(TRAINING_SCRIPT_PATH, \n",
    "                                                                                           NEW_MODEL_PATH,\n",
    "                                                                                           PIPELINE_CONFIG_PATH,\n",
    "                                                                                           number_of_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd00343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow\\models-master\\research\\object_detection\\model_main_tf2.py --model_dir=Tensorflow\\workspace\\training_demo\\models\\my_ssd_resnet50_v1_fpn --pipeline_config_path=Tensorflow\\workspace\\training_demo\\models\\my_ssd_resnet50_v1_fpn\\pipeline.config --num_train_steps=2000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89a458",
   "metadata": {},
   "source": [
    "I recommend to run this command in cmd to be able to see the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70dc7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
